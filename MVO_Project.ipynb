{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0756471",
   "metadata": {},
   "source": [
    "# Phase 1: Database Creation\n",
    "* Take my 9 proxy tickers: **XLK, XLP, XLB, XLF, XLV, XLU, XLI, AGG, AOR**\n",
    "* Create a 5 year price history of each ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83314b29",
   "metadata": {},
   "source": [
    "### Importance of 'auto_adjust=True'\n",
    "* Ensures all price columns account for any corporate actions \n",
    "* including: dividends, stock splits etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "578a16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  9 of 9 completed\n"
     ]
    }
   ],
   "source": [
    "#Importing the yfinance library\n",
    "import yfinance as yf\n",
    "\n",
    "proxy_etfs = [\"XLK\", \"XLP\", \"XLB\", \"XLF\", \"XLV\", \"XLU\", \"XLI\", \"AGG\", \"AOR\"]\n",
    "\n",
    "#Downloading historical data for each proxy ETF from January 1, 2021 to January 29, 2026\n",
    "price_data = yf.download(proxy_etfs, start=\"2005-01-01\", end=\"2026-02-05\", auto_adjust=True)\n",
    "\n",
    "#Extracting the closing prices and saving them to a CSV file\n",
    "price_table = price_data['Close']\n",
    "price_table.to_csv(\"proxy_etf_prices.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb69f0",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "* Convert Prices to Daily Log Returns\n",
    "* Generate the annualized Covariance Matrix ($\\Sigma$)\n",
    "* Calculate Risk Aversion Coefficient ($\\lambda$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d1571381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"proxy_etf_prices.csv\", index_col='Date', parse_dates=True)\n",
    "\n",
    "#Calculates all the log returns\n",
    "#Notes:\n",
    "    #df.shift(1) - finds the previous day's price for each ETF\n",
    "    #dropna() - removes any rows with NaN values that may result from the shift operation. \n",
    "    #This ensures we don't get an error for the first day which doen't have a previous day to compare to.\n",
    "def log_returns(DataFrame):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    log_returns = np.log(DataFrame/DataFrame.shift(1)).dropna()\n",
    "    log_returns.to_csv(\"proxy_etf_log_returns.csv\")\n",
    "    return log_returns\n",
    "\n",
    "log_returns = log_returns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de4ddd7",
   "metadata": {},
   "source": [
    "### What different log values mean?\n",
    "* If $P_t > P_{t-1}$ (Price went up): The ratio is greater than 1, and the log is positive.\n",
    "* If $P_t < P_{t-1}$ (Price went down): The ratio is between 0 and 1, and the log is negative\n",
    "* If $P_t = P_{t-1}$ (Price stayed the same): The ratio is exactly 1, and the log is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b8e7d",
   "metadata": {},
   "source": [
    "# Phase 2: Risk Modeling & Implied Returns\n",
    "\n",
    "Now that you have your table of **Daily Log Returns**, we need to calculate the risk relationships between your 9 sectors and determine what the market \"expects\" them to return based on your **90/10 benchmark**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. The Annualized Covariance Matrix ($\\Sigma$)\n",
    "The Covariance Matrix is the \"heart\" of the risk engine. It measures how much each sector deviates from its average and how those deviations move in sync.\n",
    "\n",
    "### The Math\n",
    "For any two sectors $i$ and $j$, the covariance is calculated as:\n",
    "$$\\sigma_{i,j} = \\frac{\\sum_{t=1}^{n} (R_{i,t} - \\bar{R}_i)(R_{j,t} - \\bar{R}_j)}{n-1}$$\n",
    "\n",
    "* **Diagonal elements:** Represent the **variance** of each sector.\n",
    "* **Off-diagonal elements:** Represent the **covariance** between different sectors.\n",
    "\n",
    "### Annualization\n",
    "Since your data is daily, but your benchmark is annual, we must scale the matrix:\n",
    "$$\\Sigma_{annual} = \\Sigma_{daily} \\times 252$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "80a63405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Covariance Matrix (Sigma):\n",
      "          AGG       AOR       XLB       XLF       XLI       XLK       XLP       XLU       XLV\n",
      "AGG  0.002371  0.000686 -0.000217 -0.001118 -0.000531 -0.000012  0.000215  0.001113 -0.000014\n",
      "AOR  0.000686  0.015929  0.021718  0.025351  0.020780  0.021409  0.011255  0.012057  0.014290\n",
      "XLB -0.000217  0.021718  0.049341  0.047762  0.040555  0.036037  0.020434  0.021650  0.025350\n",
      "XLF -0.001118  0.025351  0.047762  0.076061  0.047276  0.041406  0.023446  0.024542  0.029312\n",
      "XLI -0.000531  0.020780  0.040555  0.047276  0.043058  0.035774  0.020102  0.021478  0.024827\n",
      "XLK -0.000012  0.021409  0.036037  0.041406  0.035774  0.049622  0.018715  0.019245  0.025004\n",
      "XLP  0.000215  0.011255  0.020434  0.023446  0.020102  0.018715  0.019982  0.017848  0.016904\n",
      "XLU  0.001113  0.012057  0.021650  0.024542  0.021478  0.019245  0.017848  0.032428  0.016909\n",
      "XLV -0.000014  0.014290  0.025350  0.029312  0.024827  0.025004  0.016904  0.016909  0.027393\n"
     ]
    }
   ],
   "source": [
    "def cov_matrix(log_returns):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    cov_matrix = log_returns.cov() * 252 #Calculates the covariance matrix of the log returns\n",
    "    return cov_matrix\n",
    "\n",
    "cov_matrix = cov_matrix(log_returns)\n",
    "\n",
    "#Adjust display options to see all 9 sectors clearly\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.precision', 6)\n",
    "\n",
    "#Print the table\n",
    "print(\"Annualized Covariance Matrix (Sigma):\")\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88897d0c",
   "metadata": {},
   "source": [
    "# Phase 3: Establishing the Market Baseline\n",
    "\n",
    "Now that you have your **Annualized Covariance Matrix ($\\Sigma$)**, we need to calculate the \"Market Price of Risk\" and the returns the market implies for your 9 sectors under a **90/10 benchmark**.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Calculate Risk Aversion ($\\lambda$)\n",
    "\n",
    "The Risk Aversion Coefficient ($\\lambda$) represents the trade-off between risk and return for the entire market. It tells the model how much extra return is required for every additional unit of variance.\n",
    "\n",
    "### The Math\n",
    "$$\\lambda = \\frac{E(R_m) - R_f}{\\sigma^2_m}$$\n",
    "\n",
    "* **$E(R_m)$**: The expected annual return of your 90/10 benchmark (e.g., 0.08 for 8%).\n",
    "* **$R_f$**: The Risk-Free Rate (typically the yield on the 10-year U.S. Treasury, e.g., 0.042 for 4.2%).\n",
    "* **$\\sigma^2_m$**: The variance of the benchmark, calculated as $w_{mkt}^T \\Sigma w_{mkt}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "54f1217a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark Variance: 0.017971\n",
      "Benchamrk Standard Deviation: 0.134057\n",
      "Risk Aversion (Lambda): 2.108906\n"
     ]
    }
   ],
   "source": [
    "def eighty_twenty(cov_matrix):\n",
    "    import pandas as pd\n",
    "    #Define weights with explicit Ticker labels\n",
    "    weights_dict = {\n",
    "        'XLK': 0.18, 'XLP': 0.09, 'XLB': 0.09, 'XLF': 0.09, \n",
    "        'XLV': 0.09, 'XLU': 0.04, 'XLI': 0.09, 'AGG': 0.20, 'AOR': 0.13\n",
    "    }\n",
    "    #Create a Series and reindex it to match the Covariance Matrix exactly\n",
    "    w_series = pd.Series(weights_dict).reindex(cov_matrix.index)\n",
    "    return w_series\n",
    "\n",
    "def sixty_fourty(cov_matrix):\n",
    "    import pandas as pd\n",
    "    #Define weights with explicit Ticker labels\n",
    "    weights_dict = {\n",
    "        'XLK': 0.14, 'XLP': 0.06, 'XLB': 0.06, 'XLF': 0.07, \n",
    "        'XLV': 0.07, 'XLU': 0.03, 'XLI': 0.07, 'AGG': 0.40, 'AOR': 0.10\n",
    "    }\n",
    "    #Create a Series and reindex it to match the Covariance Matrix exactly\n",
    "    w_series = pd.Series(weights_dict).reindex(cov_matrix.index)\n",
    "    return w_series\n",
    "\n",
    "def ninety_ten(cov_matrix):\n",
    "    import pandas as pd\n",
    "    #Define weights with explicit Ticker labels\n",
    "    weights_dict = {\n",
    "        'XLK': 0.20, 'XLP': 0.10, 'XLB': 0.10, 'XLF': 0.10, \n",
    "        'XLV': 0.10, 'XLU': 0.05, 'XLI': 0.10, 'AGG': 0.10, 'AOR': 0.15\n",
    "    }\n",
    "    #Create a Series and reindex it to match the Covariance Matrix exactly\n",
    "    w_series = pd.Series(weights_dict).reindex(cov_matrix.index)\n",
    "    return w_series\n",
    "\n",
    "#Fix WEIGHTS\n",
    "#def simm_bench(cov_matrix):\n",
    "#    import pandas as pd\n",
    "    # Define weights with explicit Ticker labels\n",
    "#    weights_dict = {\n",
    "#        'XLK': 0.18, 'XLP': 0.09, 'XLB': 0.09, 'XLF': 0.09, \n",
    "#        'XLV': 0.09, 'XLU': 0.04, 'XLI': 0.09, 'AGG': 0.20, 'AOR': 0.13\n",
    "#    }\n",
    "    # Create a Series and reindex it to match the Covariance Matrix exactly\n",
    "#    w_series = pd.Series(weights_dict).reindex(cov_matrix.index)\n",
    "#    return w_series\n",
    "\n",
    "#Calculates the Benchmark variance\n",
    "def benchmark_variance(market_series, covariance_matrix):\n",
    "    return market_series.T @ covariance_matrix @ market_series\n",
    "\n",
    "#Using an 80/20 market baseline\n",
    "var = benchmark_variance(eighty_twenty(cov_matrix), cov_matrix)\n",
    "print(f\"Benchmark Variance: {var:.6f}\")\n",
    "print(f\"Benchamrk Standard Deviation: {np.sqrt(var):.6f}\")\n",
    "\n",
    "#Calculation to find lambda\n",
    "def lambda_risk_aversion(benchmark_variance):\n",
    "    E_RM = 0.08\n",
    "    RF = 0.0421\n",
    "    \n",
    "    return (E_RM-RF)/benchmark_variance\n",
    "\n",
    "\n",
    "print(f\"Risk Aversion (Lambda): {lambda_risk_aversion(var):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e85c76",
   "metadata": {},
   "source": [
    "| Value of $\\lambda$ | Sentiment | Portfolio Behavior |\n",
    "| :--- | :--- | :--- |\n",
    "| **High $\\lambda$** (e.g., 3.5+) | **Risk Averse** | The model will prefer \"safe\" sectors like Fixed Income and Utilities. It hates volatility and will sacrifice returns to avoid it. |\n",
    "| **Low $\\lambda$** (e.g., 1.5 - 2.5) | **Risk Tolerant** | The model is \"braver.\" It will aggressively allocate to high-volatility sectors like Technology and Industrials to capture higher growth. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65cf483",
   "metadata": {},
   "source": [
    "# Phase 3: Step 3 — Implied Equilibrium Returns (Π)\n",
    "\n",
    "This step is known as **Reverse Optimization**. Instead of trying to find the best weights for a set of returns, we assume that your **90/10 benchmark weights** are already optimal and calculate the returns that would justify them.\n",
    "\n",
    "### The Mathematical Formula\n",
    "$$\\Pi = \\lambda \\Sigma w_{mkt}$$\n",
    "\n",
    "* **$\\Pi$**: A vector containing the \"neutral\" expected returns for each of your 9 sectors.\n",
    "* **$\\lambda$**: The Risk Aversion Coefficient (calculated in Step 2).\n",
    "* **$\\Sigma$**: Your $9 \\times 9$ Annualized Covariance Matrix (calculated in Step 1).\n",
    "* **$w_{mkt}$**: Your benchmark weight vector (e.g., 0.10 for Fixed Income, and the remaining 0.90 distributed across equities).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "94fd11e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Implied Equilibrium Returns (Pi) ---\n",
      "    Implied Equilibrium Return\n",
      "AGG                      0.10%\n",
      "AOR                      3.15%\n",
      "XLB                      5.62%\n",
      "XLF                      6.68%\n",
      "XLI                      5.42%\n",
      "XLK                      5.61%\n",
      "XLP                      3.09%\n",
      "XLU                      3.33%\n",
      "XLV                      3.83%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the implied Equilubrium returns \n",
    "#'@' performs matrix multiplication\n",
    "\n",
    "def implied_returns(lambda_risk_aversion, cov_matrix, market):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    return lambda_risk_aversion * cov_matrix @ market\n",
    "    \n",
    "ir = implied_returns(lambda_risk_aversion(benchmark_variance(eighty_twenty(cov_matrix), cov_matrix)), cov_matrix, eighty_twenty(cov_matrix))\n",
    "\n",
    "#Create a DataFrame for better readability\n",
    "implied_df = pd.DataFrame(\n",
    "    ir, \n",
    "    index=log_returns.columns, #Use the column names from your log_returns to label the sectors\n",
    "    columns=['Implied Equilibrium Return']\n",
    ")\n",
    "\n",
    "#Format as percentages for readability\n",
    "implied_df['Implied Equilibrium Return'] = implied_df['Implied Equilibrium Return'].map(lambda x: f'{x:.2%}')\n",
    "\n",
    "print(\"--- Step 3: Implied Equilibrium Returns (Pi) ---\")\n",
    "print(implied_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "307b6588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector Order: ['AGG', 'AOR', 'XLB', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XLV']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Defining my Sector Order\n",
    "sectors = list(log_returns.columns)\n",
    "print(\"Sector Order:\", sectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d0c34e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pick Matrix (P) ---\n",
      "   AGG  AOR  XLB  XLF  XLI  XLK  XLP  XLU  XLV\n",
      "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
      "3  0.0  0.0  0.0  1.0  0.0  0.0 -1.0  0.0  0.0\n",
      "\n",
      "--- View Vector (Q) ---\n",
      "[0.05  0.06  0.035 0.02 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Define my Analyst Views\n",
    "#Relative views include a 'subsidiary' (the loser)\n",
    "#Absolute views set 'subsidiary' to None\n",
    "views_list = [\n",
    "    {'target': 'XLB', 'subsidiary': None, 'return': 0.05},  #Absolute\n",
    "    {'target': 'XLI', 'subsidiary': None, 'return': 0.06}, #Absolute\n",
    "    {'target': 'XLV', 'subsidiary': None, 'return': 0.035}, #Absolute\n",
    "    {'target': 'XLF', 'subsidiary': 'XLP', 'return': 0.02}  #Relative (XLF > XLP)\n",
    "]\n",
    "\n",
    "def view_vectors(views, sectors):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    num_views = len(views)\n",
    "    num_assets = len(sectors)\n",
    "    \n",
    "    #Initialize P and Q\n",
    "    P = np.zeros((num_views, num_assets))\n",
    "    Q = np.zeros(num_views)\n",
    "    \n",
    "    for i, view in enumerate(views):\n",
    "        #Handle the Pick Matrix (P)\n",
    "        #Set the target (Winner)\n",
    "        P[i, sectors.index(view['target'])] = 1\n",
    "        \n",
    "        # et the subsidiary (Loser) if it exists\n",
    "        if view['subsidiary']:\n",
    "            P[i, sectors.index(view['subsidiary'])] = -1\n",
    "            \n",
    "        #Handle the View Vector (Q)\n",
    "        #This always takes the expected return value\n",
    "        Q[i] = view['return']\n",
    "        \n",
    "    return P, Q\n",
    "\n",
    "P, Q = view_vectors(views_list, sectors)\n",
    "\n",
    "print(\"\\n--- Pick Matrix (P) ---\")\n",
    "print(pd.DataFrame(P, columns=sectors))\n",
    "print(\"\\n--- View Vector (Q) ---\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eedb8c1",
   "metadata": {},
   "source": [
    "### **Think of it this way:** \n",
    "$P$ and $Q$ tell the model what you think; $\\tau$ and $\\Omega$ tell the model how much to care about what you think.\n",
    "* $\\tau$ represents how much you trust the \"Market Baseline\" ($\\Pi$) relative to your own data. (Note 0.025 is the standard)\n",
    "* $\\Omega$ is the certainty of the analysts views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18df67",
   "metadata": {},
   "source": [
    "I will use the The He-Litterman Method to find my omega.\n",
    "\n",
    "This method takes my Covariance Matrix ($\\Sigma$), and assumes our confidence in our views is proportional to the corresponding  sector's volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9b1c1709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty Matrix (Omega):\n",
      "[[0.00123352 0.         0.         0.        ]\n",
      " [0.         0.00107645 0.         0.        ]\n",
      " [0.         0.         0.00068484 0.        ]\n",
      " [0.         0.         0.         0.00122879]]\n"
     ]
    }
   ],
   "source": [
    "#Calculate Omega (The uncertainty of the analyst views)\n",
    "#This creates a diagonal matrix representing the variance of your views\n",
    "#'He-Litterman' method: Omega = diag(P * (tau * Sigma) * P.T)\n",
    "\n",
    "def omega(P_matrix, covariance_matrix):\n",
    "    import numpy as np\n",
    "    TAU = 0.025\n",
    "    \n",
    "    omega = np.diag(np.diag(P_matrix @ (TAU * covariance_matrix) @ P_matrix.T))\n",
    "    return omega\n",
    "\n",
    "print(\"Uncertainty Matrix (Omega):\")\n",
    "omega = omega(P, cov_matrix)\n",
    "print(omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b8f446bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_bl(cov_matrix, P_matrix, Q_matrix, omega, implied_returns):\n",
    "    TAU = 0.025\n",
    "    \n",
    "    #Calculate the 'Prior' precision (Tau * Sigma)^-1\n",
    "    precision_prior = np.linalg.inv(TAU * cov_matrix)\n",
    "\n",
    "    #Calculate the 'View' precision (P.T * Omega^-1 * P)\n",
    "    precision_view = P_matrix.T @ np.linalg.inv(omega) @ P_matrix\n",
    "\n",
    "    #Calculate the combined returns (Mu_BL)\n",
    "    #Formula: [(Prior_Prec + View_Prec)^-1] @ [Prior_Prec @ Pi + P.T @ Omega^-1 @ Q]\n",
    "    term1 = np.linalg.inv(precision_prior + precision_view)\n",
    "    term2 = (precision_prior @ implied_returns) + (P_matrix.T @ np.linalg.inv(omega) @ Q_matrix)\n",
    "    \n",
    "    mu_bl = term1 @ term2\n",
    "    return mu_bl\n",
    "mu_bl = mu_bl(cov_matrix, P, Q, omega, ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc229d",
   "metadata": {},
   "source": [
    "## **Final Phase:**\n",
    "### **Running the Black-Litterman Utility Formula**\n",
    "The Master Formula:$$\\mu_{BL} = [(\\tau \\Sigma)^{-1} + P^T \\Omega^{-1} P]^{-1} [(\\tau \\Sigma)^{-1} \\Pi + P^T \\Omega^{-1} Q]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4f646dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Black-Litterman Portfolio Analysis ---\n",
      "          Sector Name Market Implied (Pi) Analyst View (Q) BL Combined (Mu) Total Return (Exp)\n",
      "AGG      Fixed Income               0.10%                -            0.11%              4.32%\n",
      "AOR             Mixed               3.15%                -            3.02%              7.23%\n",
      "XLB         Materials               5.62%            5.00%            5.33%              9.54%\n",
      "XLF        Financials               6.68%            2.00%            6.03%             10.24%\n",
      "XLI       Industrials               5.42%            6.00%            5.24%              9.45%\n",
      "XLK        Technology               5.61%                -            5.41%              9.62%\n",
      "XLP  Consumer Staples               3.09%                -            3.13%              7.34%\n",
      "XLU         Utilities               3.33%                -            3.32%              7.53%\n",
      "XLV        Healthcare               3.83%            3.50%            3.69%              7.90%\n"
     ]
    }
   ],
   "source": [
    "#Define the Sector Mapping (Matches your 9 sectors)\n",
    "sector_names = {\n",
    "    'XLK': 'Technology',\n",
    "    'XLP': 'Consumer Staples',\n",
    "    'XLB': 'Materials',\n",
    "    'XLF': 'Financials',\n",
    "    'XLV': 'Healthcare',\n",
    "    'XLU': 'Utilities',\n",
    "    'XLI': 'Industrials',\n",
    "    'AGG': 'Fixed Income',\n",
    "    'AOR': 'Mixed'\n",
    "}\n",
    "\n",
    "#Correct the View Mapping \n",
    "#This ensures analyst views appear in the right row even if you only have one view\n",
    "view_dict = {}\n",
    "for i in range(len(Q)):\n",
    "    #Find which sector index has the '1' in this row of P\n",
    "    sector_idx = np.where(P[i] == 1)[0][0]\n",
    "    view_dict[sectors[sector_idx]] = Q[i]\n",
    "\n",
    "#Create the comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Sector Name': [sector_names.get(s, s) for s in sectors], #Mapping tickers to Names\n",
    "    'Market Implied (Pi)': ir,\n",
    "    'Analyst View (Q)': [view_dict.get(s, np.nan) for s in sectors],\n",
    "    'BL Combined (Mu)': mu_bl\n",
    "}, index=sectors)\n",
    "\n",
    "#Add the 'Total' Return (Adding Risk-Free Rate back)\n",
    "comparison_df['Total Return (Exp)'] = comparison_df['BL Combined (Mu)'] + 0.0421 #risk free rate\n",
    "\n",
    "print(\"--- Final Black-Litterman Portfolio Analysis ---\")\n",
    "\n",
    "#Apply formatting\n",
    "def format_perc(val):\n",
    "    if isinstance(val, str): return val\n",
    "    if pd.isna(val): return \"-\"\n",
    "    return f\"{val:.2%}\"\n",
    "#tries .map first and if it is the wrong version it will use .applymap\n",
    "try:\n",
    "    print(comparison_df.map(format_perc))\n",
    "except AttributeError:\n",
    "    print(comparison_df.applymap(format_perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bccd9c",
   "metadata": {},
   "source": [
    "## Reading the results:\n",
    "* ### If $\\mu_{BL}$ is higher than the market implied return , you will increase your position from the current weight.\n",
    "* ### If $\\mu_{BL}$ is lower for Consumer Staples (XLP), you will harvest those gains and move them elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f467f07",
   "metadata": {},
   "source": [
    "## Interpreting the Model\n",
    "This model tells us how to adjust sector weights based on our views assuming they are at the market baseline given. So if the model shows that industrials is undervalued and its weight should be increased. It is saying increase the weight from the current benchmark you inputted. \n",
    "\n",
    "First look at your portfolio because you may already be sitting above the benchamrk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
